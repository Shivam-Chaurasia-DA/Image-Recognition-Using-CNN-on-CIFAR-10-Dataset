+*In[5]:*+
[source, ipython3]
----
import keras
from keras.datasets import cifar10
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D
from pathlib import Path
from keras.utils import to_categorical
----


+*In[6]:*+
[source, ipython3]
----
from keras.datasets import cifar10

(x_train, y_train), (x_test, y_test) = cifar10.load_data()
----


+*In[7]:*+
[source, ipython3]
----
x_train=x_train.astype('float32')
x_test=x_test.astype('float32')
x_train/=255.0
x_test/=255.0
----


+*In[8]:*+
[source, ipython3]
----
from keras.utils import to_categorical

y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)
----


+*In[9]:*+
[source, ipython3]
----
model=Sequential()
model.add(Conv2D(32,(3,3), padding='same', input_shape=(32,32,3), activation='relu'))
model.add(Conv2D(32,(3,3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))

model.add(Conv2D(64,(3,3), padding='same', activation='relu'))
model.add(Conv2D(32,(3,3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(10, activation='softmax'))
----


+*In[11]:*+
[source, ipython3]
----
model.compile(
    loss='categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy'])

model.summary()
----


+*Out[11]:*+
----
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 32, 32, 32)        896       
                                                                 
 conv2d_1 (Conv2D)           (None, 30, 30, 32)        9248      
                                                                 
 max_pooling2d (MaxPooling2  (None, 15, 15, 32)        0         
 D)                                                              
                                                                 
 dropout (Dropout)           (None, 15, 15, 32)        0         
                                                                 
 conv2d_2 (Conv2D)           (None, 15, 15, 64)        18496     
                                                                 
 conv2d_3 (Conv2D)           (None, 13, 13, 32)        18464     
                                                                 
 max_pooling2d_1 (MaxPoolin  (None, 6, 6, 32)          0         
 g2D)                                                            
                                                                 
 dropout_1 (Dropout)         (None, 6, 6, 32)          0         
                                                                 
 flatten (Flatten)           (None, 1152)              0         
                                                                 
 dense (Dense)               (None, 512)               590336    
                                                                 
 dropout_2 (Dropout)         (None, 512)               0         
                                                                 
 dense_1 (Dense)             (None, 10)                5130      
                                                                 
=================================================================
Total params: 642570 (2.45 MB)
Trainable params: 642570 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
----


+*In[12]:*+
[source, ipython3]
----
model.fit(
    x_train,
    y_train,
    batch_size=32,
    epochs=10,
    validation_data=(x_test, y_test),
    shuffle=True
)
----


+*Out[12]:*+
----
Epoch 1/10
1563/1563 [==============================] - 223s 141ms/step - loss: 1.5590 - accuracy: 0.4292 - val_loss: 1.2033 - val_accuracy: 0.5605
Epoch 2/10
1563/1563 [==============================] - 193s 123ms/step - loss: 1.1801 - accuracy: 0.5791 - val_loss: 0.9969 - val_accuracy: 0.6438
Epoch 3/10
1563/1563 [==============================] - 200s 128ms/step - loss: 1.0244 - accuracy: 0.6392 - val_loss: 0.8692 - val_accuracy: 0.6978
Epoch 4/10
1563/1563 [==============================] - 214s 137ms/step - loss: 0.9358 - accuracy: 0.6686 - val_loss: 0.8590 - val_accuracy: 0.7065
Epoch 5/10
1563/1563 [==============================] - 207s 133ms/step - loss: 0.8773 - accuracy: 0.6916 - val_loss: 0.7793 - val_accuracy: 0.7308
Epoch 6/10
1563/1563 [==============================] - 235s 150ms/step - loss: 0.8279 - accuracy: 0.7082 - val_loss: 0.7395 - val_accuracy: 0.7396
Epoch 7/10
1563/1563 [==============================] - 191s 122ms/step - loss: 0.7945 - accuracy: 0.7208 - val_loss: 0.7430 - val_accuracy: 0.7434
Epoch 8/10
1563/1563 [==============================] - 183s 117ms/step - loss: 0.7650 - accuracy: 0.7306 - val_loss: 0.7095 - val_accuracy: 0.7579
Epoch 9/10
1563/1563 [==============================] - 182s 116ms/step - loss: 0.7421 - accuracy: 0.7400 - val_loss: 0.7260 - val_accuracy: 0.7517
Epoch 10/10
1563/1563 [==============================] - 183s 117ms/step - loss: 0.7149 - accuracy: 0.7491 - val_loss: 0.7098 - val_accuracy: 0.7541
<keras.src.callbacks.History at 0x15f3acb5010>----


+*In[13]:*+
[source, ipython3]
----
model_structure = model.to_json()
f = Path("model_structure.json")
f.write_text(model_structure)
----


+*Out[13]:*+
----6342----


+*In[14]:*+
[source, ipython3]
----
model.save_weights("model_weight.h5")
----


+*In[15]:*+
[source, ipython3]
----
from keras.models import model_from_json
from pathlib import Path
from keras.preprocessing import image
import numpy as np
----


+*In[16]:*+
[source, ipython3]
----
class_labels=[
    "planes",
    "car",
    "bird",
    "cat",
    "deer",
    "dog",
    "frog",
    "horse",
    "boat",
    "truck"
]
----


+*In[17]:*+
[source, ipython3]
----
f = Path("model_structure.json")
model_structure = f.read_text()
----


+*In[18]:*+
[source, ipython3]
----
model = model_from_json(model_structure)
----


+*In[19]:*+
[source, ipython3]
----
model.load_weights("model_weight.h5")
----


+*In[20]:*+
[source, ipython3]
----
import matplotlib.pyplot as plt
from tensorflow.keras.utils import load_img, img_to_array
img = load_img("C:/Users/TEMP.RYZENFIVE.008/OneDrive/Desktop/ripV/truck.jpg", target_size = (32,32))
plt.imshow(img)
----


+*Out[20]:*+
----<matplotlib.image.AxesImage at 0x15f3b697ed0>
![png](output_14_1.png)
----


+*In[21]:*+
[source, ipython3]
----
from tensorflow.keras.utils import img_to_array
image_to_test = img_to_array(img)

list_of_images = np.expand_dims(image_to_test, axis = 0)
----


+*In[22]:*+
[source, ipython3]
----
results = model.predict(list_of_images)
----


+*Out[22]:*+
----
1/1 [==============================] - 0s 254ms/step
----


+*In[23]:*+
[source, ipython3]
----
single_result = results[0]
----


+*In[24]:*+
[source, ipython3]
----
most_likely_class_index = int(np.argmax(single_result))
class_likelihood = single_result[most_likely_class_index]


----


+*In[25]:*+
[source, ipython3]
----
class_label = class_labels[most_likely_class_index]
----


+*In[26]:*+
[source, ipython3]
----
print("This is a image is a {} likelihood: {:.2f}".format(class_label, class_likelihood))

----


+*Out[26]:*+
----
This is a image is a truck likelihood: 1.00
----
